(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{275:function(e,t,a){e.exports=a.p+"assets/img/input_sets.2ebbce06.svg"},276:function(e,t,a){e.exports=a.p+"assets/img/fired_rules.09c73efe.svg"},308:function(e,t,a){"use strict";a.r(t);var n=a(14),s=Object(n.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h1",{attrs:{id:"frontmatter-title"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#frontmatter-title"}},[e._v("#")]),e._v(" "+e._s(e.$frontmatter.title))]),e._v(" "),t("p",[e._v("This was a small side project I used as an introduction to my PhD field of\nresearch. The idea was to use a SCADA system as an interface for control of the\nlights and develop an intelligent agent capable of properly controlling them\nusing SCADA's interface. The result was an agent that connects to the SCADA\nand, using a webcam, determines whether the lights in the room should be\namplified or lowered. User of the system could also affect the preferred\nillumination levels using hand gestures. This was the result:")]),e._v(" "),t("iframe",{attrs:{width:"560",height:"315",src:"https://www.youtube.com/embed/IprXwcsyk9Q",frameborder:"0",allow:"autoplay; encrypted-media",allowfullscreen:""}}),e._v(" "),t("p",[e._v("To clarify, Bri is the measured brightness of the current frame, Pref is the\npreferred brightness of the current frame and Req is the approximated light\nincrease/decrease percentage.")]),e._v(" "),t("h2",{attrs:{id:"how-it-works"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#how-it-works"}},[e._v("#")]),e._v(" How it works")]),e._v(" "),t("h3",{attrs:{id:"lights"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#lights"}},[e._v("#")]),e._v(" Lights")]),e._v(" "),t("p",[e._v("In my apartment I use Phillips Hue light bulbs. The light bulbs connect to a\ndevice called the Hue bridge. The bridge offers a REST interface that various\napplications can use to control the light bulbs - turn them on/off, dim them or\neven change colors (depending on what the lightbulb supports).")]),e._v(" "),t("h3",{attrs:{id:"scada"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#scada"}},[e._v("#")]),e._v(" SCADA")]),e._v(" "),t("p",[e._v("For the SCADA system I used an early prototype of Konƒçar's new SCADA system. I\ncan't really go into details of the implementation here as the software is\ncommercial and I'm contracted under an NDA. What I can say is that I used it to\nconnect to the Hue bridge service (with some tweaks) and it provided an\ninterface that the intelligent agent used to increase or decrease the lights.")]),e._v(" "),t("h3",{attrs:{id:"intelligent-agent"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#intelligent-agent"}},[e._v("#")]),e._v(" Intelligent agent")]),e._v(" "),t("p",[e._v("The workflow of the intelligent agent was such that every second it would\nconnect to the webcam, get the current picture and decide whether it should\nincrease or decrease the lights (or keep them at the same level). This workflow\nwas implemented through a feedback loop, where the agent in every iteration had\nits previous state and the current image, result of the iteration would be\ndelta indicating the change in lightning level and the update of the agent's\nstate. The state contained a series of previous images and a variable that\nrepresents the currently preferred brightness. The analysis of the current\nimage and calculated result can be split into three categories: brightness\ncalculation, face detection, gesture recognition and fuzzy inference.")]),e._v(" "),t("h4",{attrs:{id:"brightness-calculation"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#brightness-calculation"}},[e._v("#")]),e._v(" Brightness calculation")]),e._v(" "),t("p",[e._v("This one started out simple, but I managed to complicate it in order to get\nbetter results. Initially, I would simply just take every pixel of the current\nimage in greyscale, average the values over the picture and use this as the\ncurrent brightness. This proved to be a bit problematic because if someone got\ninto the picture that was, for instance, wearing a black shirt, the agent would\nthink that the room got darker. In order to counter this, I've made the agent\nstore the images it gets into its state (and delete old ones after some time).\nImages from the previous iterations would give me insight to temporal changes\nin the picture - enabling it do detect which pixels change brightness rapidly.\nThe pixels that change brightness rapidly are more probable to be moving\nobjects, making them less relevant in the brightness calculation, giving\nadvantage to pixels that represent, for instance, walls. Brightness is then\ncalculated as a weighted average where weights are these relevancies. This\napproach is still not perfect, but it works better than the basic one.")]),e._v(" "),t("p",[e._v("The following video demonstrates how this calculation works in practice, the\nwhite pixels are more relevant then the grey or black ones:")]),e._v(" "),t("iframe",{attrs:{width:"560",height:"315",src:"https://www.youtube.com/embed/i8Yhj5-mtTo",frameborder:"0",allow:"autoplay; encrypted-media",allowfullscreen:""}}),e._v(" "),t("h4",{attrs:{id:"face-detection"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#face-detection"}},[e._v("#")]),e._v(" Face detection")]),e._v(" "),t("p",[e._v("One of the conclusions the agent can draw from the image is whether any people\nare in the scene. If there are people, it should increase the preferred\nbrightness. For this, openCV's\n"),t("a",{attrs:{href:"https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_alt.xml",target:"_blank",rel:"noopener noreferrer"}},[e._v("Haar cascading features model"),t("OutboundLink")],1),e._v("\nwas used. This model proved to work well out of the box, so no further\nalterations were required to solve this problem.")]),e._v(" "),t("h4",{attrs:{id:"gesture-recognition"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#gesture-recognition"}},[e._v("#")]),e._v(" Gesture recognition")]),e._v(" "),t("p",[e._v('This is where things got interesting. I wanted to be able to be set preferred\nbrightness using hand gestures, open fist meaning "increase light", closed fist\nmeaning "reduce light". I started looking up tutorials how to detect human skin\nand separate hands from backgrounds in the picture. I learned about different\nimage filtration methods and creating contours and convex hulls.')]),e._v(" "),t("p",[e._v("I was a bit inpatient and wanted results fast, so I ditched this approach\nearly, and decided to use a CNN. I bypassed the changing backgrounds problem by\nfixing an image area and only performing gesture recognition there (red\nrectangle in the first video). Since the leftmost pixel columns and upper rows\nwere rarely going to be used (hand doesn't go there often), I used these pixels\nto define what color is the background, turning my refrigerator into an\nimprovised greenscreen. This made the hand detection much more efficient\n(unless a refrigerator-colored alien was using the system). After that, a CNN\nwas trained on different images of my opened or closed fist, which gave\nsatisfying gesture detections.")]),e._v(" "),t("p",[e._v('This was used to update the currently preferred brightness - open fist\nincreases it, closed decreases. This can be seen on the first video written\nunder the "Pref" field.')]),e._v(" "),t("h4",{attrs:{id:"fuzzy-inference"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#fuzzy-inference"}},[e._v("#")]),e._v(" Fuzzy inference")]),e._v(" "),t("p",[e._v("With the last three calculations the agent has everything it needs in order to\ndecide how current lightning level should change. What it needs is the\nimplementation that takes these values and calculates the delta. I used fuzzy\nlogic here with two simple rules:")]),e._v(" "),t("ul",[t("li",[e._v("If the room is too dark, increase light")]),e._v(" "),t("li",[e._v("If the room is too light, decrease light")])]),e._v(" "),t("p",[e._v("Whether the room is too dark or too light is decided using the preferred\nbrightness. I modeled these variables as a sigmoid whose offset is determined\nby the preferred brightness. Increase and decrease light are modeled as\nsigmoids as well. The following figures demonstrate values of these variables\n(if current preferred brightness is 20):")]),e._v(" "),t("p",[t("img",{attrs:{src:a(275),alt:"Dark and light sets"}})]),e._v(" "),t("p",[e._v('For implications in the individual rules, I simply used the minimum function\nand for rule result accumulation I used maximum. So if the camera measured that\nthe room was too dark, that would manifest with the following rule "firings":')]),e._v(" "),t("p",[t("img",{attrs:{src:a(276),alt:"Fired rules"}})]),e._v(" "),t("p",[e._v("In the end, I used center of area to determine a concrete, single value as an\noutput, which in above example would accumulate to 0.35, indicating an increase\nin lightning by approximately 35%.")]),e._v(" "),t("h2",{attrs:{id:"conclusion"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#conclusion"}},[e._v("#")]),e._v(" Conclusion")]),e._v(" "),t("p",[e._v("This was a useful project mostly because it taught me new things about AI\nintegration in SCADA systems, gesture recognition and tools from openCV in\ngeneral (this was my first practical use of it). It was also a nice revision of\nCNNs in Tensorflow and implementations of fuzzy inference systems. It served\nas a nice, fun introduction to my field of research for my PhD.")]),e._v(" "),t("p",[e._v("Practically, however, I don't see too much application for this system, mostly\nbecause it requires a camera in order to control lighting. This itself is a\nsomewhat flawed approach because a number of things could go wrong:")]),e._v(" "),t("ul",[t("li",[e._v("If a person is not right in the scene, the camera won't detect it and\nincrease the light, the room isn't completely covered.")]),e._v(" "),t("li",[e._v("The camera needs to see a face in order to increase the light, which means\nit needs to be able to find a face in the dark first - which puts us in a\nchicken-or-the-egg kind of scenario.")])]),e._v(" "),t("p",[e._v("The camera approach is definitely not perfect, but it could make sense to use\nit combined with some other methods, i.e. vocal control or a GUI over which the\npreferred brightness can be changed.")])])}),[],!1,null,null,null);t.default=s.exports}}]);