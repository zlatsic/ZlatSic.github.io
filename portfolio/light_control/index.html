<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Light control using computer vision | Zlatan Sičanica</title>
    <meta name="generator" content="VuePress 1.9.7">
    <link rel="icon" type="image/svg" href="/favicon.svg">
    <script async="true" src="https://www.googletagmanager.com/gtag/js?id=G-9M3HSNDJLW"></script>
    <script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-9M3HSNDJLW');</script>
    <meta name="description" content="Web and AI developer">
    
    <link rel="preload" href="/assets/css/0.styles.45178bce.css" as="style"><link rel="preload" href="/assets/js/app.b6ec3d76.js" as="script"><link rel="preload" href="/assets/js/2.63a97bf5.js" as="script"><link rel="preload" href="/assets/js/13.e9388910.js" as="script"><link rel="preload" href="/assets/js/4.8d83e01b.js" as="script"><link rel="prefetch" href="/assets/js/10.289a6095.js"><link rel="prefetch" href="/assets/js/11.619583c8.js"><link rel="prefetch" href="/assets/js/12.a0dd6ca5.js"><link rel="prefetch" href="/assets/js/14.e32ea9f3.js"><link rel="prefetch" href="/assets/js/15.d7e82046.js"><link rel="prefetch" href="/assets/js/16.66aa96a8.js"><link rel="prefetch" href="/assets/js/17.67a34c5a.js"><link rel="prefetch" href="/assets/js/18.46911f93.js"><link rel="prefetch" href="/assets/js/19.5941b991.js"><link rel="prefetch" href="/assets/js/20.9d0566ad.js"><link rel="prefetch" href="/assets/js/21.4baa125f.js"><link rel="prefetch" href="/assets/js/22.225fe51c.js"><link rel="prefetch" href="/assets/js/23.c53168ab.js"><link rel="prefetch" href="/assets/js/24.6c0a6f9d.js"><link rel="prefetch" href="/assets/js/25.468624e6.js"><link rel="prefetch" href="/assets/js/26.7a5f504f.js"><link rel="prefetch" href="/assets/js/27.9811aec1.js"><link rel="prefetch" href="/assets/js/28.0af89c48.js"><link rel="prefetch" href="/assets/js/29.4ec88b3f.js"><link rel="prefetch" href="/assets/js/3.64c7bb25.js"><link rel="prefetch" href="/assets/js/30.b0e46bab.js"><link rel="prefetch" href="/assets/js/31.a2d820bf.js"><link rel="prefetch" href="/assets/js/32.5fe47d04.js"><link rel="prefetch" href="/assets/js/5.aaf5e9e5.js"><link rel="prefetch" href="/assets/js/6.965fa643.js"><link rel="prefetch" href="/assets/js/7.fa6771ae.js"><link rel="prefetch" href="/assets/js/8.6c559318.js"><link rel="prefetch" href="/assets/js/9.58d66674.js">
    <link rel="stylesheet" href="/assets/css/0.styles.45178bce.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div id="global-layout"><div class="content"><div class="theme-container no-sidebar"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Zlatan Sičanica</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/blog/" class="nav-link">
  Blog
</a></div><div class="nav-item"><a href="/portfolio/" class="nav-link router-link-active">
  Portfolio
</a></div><div class="nav-item"><a href="/cv.html" class="nav-link">
  CV
</a></div><div class="nav-item"><a href="/contact.html" class="nav-link">
  Contact
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/blog/" class="nav-link">
  Blog
</a></div><div class="nav-item"><a href="/portfolio/" class="nav-link router-link-active">
  Portfolio
</a></div><div class="nav-item"><a href="/cv.html" class="nav-link">
  CV
</a></div><div class="nav-item"><a href="/contact.html" class="nav-link">
  Contact
</a></div> <!----></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="frontmatter-title"><a href="#frontmatter-title" class="header-anchor">#</a> Light control using computer vision</h1> <p>This was a small side project I used as an introduction to my PhD field of
research. The idea was to use a SCADA system as an interface for control of the
lights and develop an intelligent agent capable of properly controlling them
using SCADA's interface. The result was an agent that connects to the SCADA
and, using a webcam, determines whether the lights in the room should be
amplified or lowered. User of the system could also affect the preferred
illumination levels using hand gestures. This was the result:</p> <iframe width="560" height="315" src="https://www.youtube.com/embed/IprXwcsyk9Q" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="allowfullscreen"></iframe> <p>To clarify, Bri is the measured brightness of the current frame, Pref is the
preferred brightness of the current frame and Req is the approximated light
increase/decrease percentage.</p> <h2 id="how-it-works"><a href="#how-it-works" class="header-anchor">#</a> How it works</h2> <h3 id="lights"><a href="#lights" class="header-anchor">#</a> Lights</h3> <p>In my apartment I use Phillips Hue light bulbs. The light bulbs connect to a
device called the Hue bridge. The bridge offers a REST interface that various
applications can use to control the light bulbs - turn them on/off, dim them or
even change colors (depending on what the lightbulb supports).</p> <h3 id="scada"><a href="#scada" class="header-anchor">#</a> SCADA</h3> <p>For the SCADA system I used an early prototype of Končar's new SCADA system. I
can't really go into details of the implementation here as the software is
commercial and I'm contracted under an NDA. What I can say is that I used it to
connect to the Hue bridge service (with some tweaks) and it provided an
interface that the intelligent agent used to increase or decrease the lights.</p> <h3 id="intelligent-agent"><a href="#intelligent-agent" class="header-anchor">#</a> Intelligent agent</h3> <p>The workflow of the intelligent agent was such that every second it would
connect to the webcam, get the current picture and decide whether it should
increase or decrease the lights (or keep them at the same level). This workflow
was implemented through a feedback loop, where the agent in every iteration had
its previous state and the current image, result of the iteration would be
delta indicating the change in lightning level and the update of the agent's
state. The state contained a series of previous images and a variable that
represents the currently preferred brightness. The analysis of the current
image and calculated result can be split into three categories: brightness
calculation, face detection, gesture recognition and fuzzy inference.</p> <h4 id="brightness-calculation"><a href="#brightness-calculation" class="header-anchor">#</a> Brightness calculation</h4> <p>This one started out simple, but I managed to complicate it in order to get
better results. Initially, I would simply just take every pixel of the current
image in greyscale, average the values over the picture and use this as the
current brightness. This proved to be a bit problematic because if someone got
into the picture that was, for instance, wearing a black shirt, the agent would
think that the room got darker. In order to counter this, I've made the agent
store the images it gets into its state (and delete old ones after some time).
Images from the previous iterations would give me insight to temporal changes
in the picture - enabling it do detect which pixels change brightness rapidly.
The pixels that change brightness rapidly are more probable to be moving
objects, making them less relevant in the brightness calculation, giving
advantage to pixels that represent, for instance, walls. Brightness is then
calculated as a weighted average where weights are these relevancies. This
approach is still not perfect, but it works better than the basic one.</p> <p>The following video demonstrates how this calculation works in practice, the
white pixels are more relevant then the grey or black ones:</p> <iframe width="560" height="315" src="https://www.youtube.com/embed/i8Yhj5-mtTo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="allowfullscreen"></iframe> <h4 id="face-detection"><a href="#face-detection" class="header-anchor">#</a> Face detection</h4> <p>One of the conclusions the agent can draw from the image is whether any people
are in the scene. If there are people, it should increase the preferred
brightness. For this, openCV's
<a href="https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_alt.xml" target="_blank" rel="noopener noreferrer">Haar cascading features model<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
was used. This model proved to work well out of the box, so no further
alterations were required to solve this problem.</p> <h4 id="gesture-recognition"><a href="#gesture-recognition" class="header-anchor">#</a> Gesture recognition</h4> <p>This is where things got interesting. I wanted to be able to be set preferred
brightness using hand gestures, open fist meaning &quot;increase light&quot;, closed fist
meaning &quot;reduce light&quot;. I started looking up tutorials how to detect human skin
and separate hands from backgrounds in the picture. I learned about different
image filtration methods and creating contours and convex hulls.</p> <p>I was a bit inpatient and wanted results fast, so I ditched this approach
early, and decided to use a CNN. I bypassed the changing backgrounds problem by
fixing an image area and only performing gesture recognition there (red
rectangle in the first video). Since the leftmost pixel columns and upper rows
were rarely going to be used (hand doesn't go there often), I used these pixels
to define what color is the background, turning my refrigerator into an
improvised greenscreen. This made the hand detection much more efficient
(unless a refrigerator-colored alien was using the system). After that, a CNN
was trained on different images of my opened or closed fist, which gave
satisfying gesture detections.</p> <p>This was used to update the currently preferred brightness - open fist
increases it, closed decreases. This can be seen on the first video written
under the &quot;Pref&quot; field.</p> <h4 id="fuzzy-inference"><a href="#fuzzy-inference" class="header-anchor">#</a> Fuzzy inference</h4> <p>With the last three calculations the agent has everything it needs in order to
decide how current lightning level should change. What it needs is the
implementation that takes these values and calculates the delta. I used fuzzy
logic here with two simple rules:</p> <ul><li>If the room is too dark, increase light</li> <li>If the room is too light, decrease light</li></ul> <p>Whether the room is too dark or too light is decided using the preferred
brightness. I modeled these variables as a sigmoid whose offset is determined
by the preferred brightness. Increase and decrease light are modeled as
sigmoids as well. The following figures demonstrate values of these variables
(if current preferred brightness is 20):</p> <p><img src="/assets/img/input_sets.2ebbce06.svg" alt="Dark and light sets"></p> <p>For implications in the individual rules, I simply used the minimum function
and for rule result accumulation I used maximum. So if the camera measured that
the room was too dark, that would manifest with the following rule &quot;firings&quot;:</p> <p><img src="/assets/img/fired_rules.09c73efe.svg" alt="Fired rules"></p> <p>In the end, I used center of area to determine a concrete, single value as an
output, which in above example would accumulate to 0.35, indicating an increase
in lightning by approximately 35%.</p> <h2 id="conclusion"><a href="#conclusion" class="header-anchor">#</a> Conclusion</h2> <p>This was a useful project mostly because it taught me new things about AI
integration in SCADA systems, gesture recognition and tools from openCV in
general (this was my first practical use of it). It was also a nice revision of
CNNs in Tensorflow and implementations of fuzzy inference systems. It served
as a nice, fun introduction to my field of research for my PhD.</p> <p>Practically, however, I don't see too much application for this system, mostly
because it requires a camera in order to control lighting. This itself is a
somewhat flawed approach because a number of things could go wrong:</p> <ul><li>If a person is not right in the scene, the camera won't detect it and
increase the light, the room isn't completely covered.</li> <li>The camera needs to see a face in order to increase the light, which means
it needs to be able to find a face in the dark first - which puts us in a
chicken-or-the-egg kind of scenario.</li></ul> <p>The camera approach is definitely not perfect, but it could make sense to use
it combined with some other methods, i.e. vocal control or a GUI over which the
preferred brightness can be changed.</p></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div></div> <footer><div class="social"><span>Social:</span> <a href="https://github.com/zlatsic" target="blank_"><span class="ri-github-line icon"></span> <span class="label"> GitHub </span></a><a href="https://linkedin.com/in/zlatsic/" target="blank_"><span class="ri-linkedin-box-line icon"></span> <span class="label"> LinkedIn </span></a><a href="https://twitter.com/zlatsic" target="blank_"><span class="ri-twitter-line icon"></span> <span class="label"> Twitter </span></a><a href="https://instagram.com/zlatsic/" target="blank_"><span class="ri-instagram-line icon"></span> <span class="label"> Instagram </span></a><a href="https://youtube.com/channel/UCCbEay_pbywwDnoMZzxqaow" target="blank_"><span class="ri-youtube-line icon"></span> <span class="label"> YouTube </span></a></div> <span class="copyright">
            © 2024, Zlatan Sičanica
        </span></footer> <div class="wrapper"><div class="cookies-dialogue"><span>This website uses cookies to analyze user traffic. false</span> <button>Dismiss</button></div></div></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.b6ec3d76.js" defer></script><script src="/assets/js/2.63a97bf5.js" defer></script><script src="/assets/js/13.e9388910.js" defer></script><script src="/assets/js/4.8d83e01b.js" defer></script>
  </body>
</html>
